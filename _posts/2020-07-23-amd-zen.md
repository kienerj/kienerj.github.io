---
layout: post
title: AMD Zen-based CPUs
subtitle: About Intel MKL performance
tags: [hardware,performance]
comments: true
---

## UPDATE August 18th, 2020:

I just learned that newest version MKL 2020.1 fixed this loophole to make it play nice with AMD CPUs. A quick check also showed that anaconda already switched to this new version and hence the situation is pretty dire for using AMD CPU on Windows with Anaconda Python if you care about numpy performance.

Prior to learning about the now closed loophole I already played around with using OpenBLAS, which would also work nice on AMD CPUs but I had limited success. I have to check again but as far as I remember there is no scipy build for windows for OpenBLAS on anaconda and once you try to update or install new packages conda always wants to revert to mkl.

Again this is only a problem on Windows as for Linux and MacOS there is the `nomkl`package.

--------------------------------------------

Computer hardware is something I'm very interested in. Knowing the performance of 
hardware can really help in analyzing bottlenecks or simply making cost-effective 
purchase decisions.

## Need a powerful workstation?

At latest since the release of AMDs Zen2 based CPUs under the Ryzen, Threadripper and
Eypc brands, AMD has become a real competition to Intel again offering significantly
better multi-threaded performance at similar price points. In fact a Workstation with a
64-core Threadripper CPU, a RTX-series based NVIDIA GPU for CUDA/deep learning, 128+GB
of RAM and plenty of SSD storage can be had for around $10K easily. Even for 5K you can
build yourself a very nice workstation.

## RTX Gaming GPUs for AI

I digress but RTX gaming cards are just fine for deep learning as long as you use them
on your local machine directly. As far as I know virtualization, if at all, only works
with a Linux host. But even then if you need Windows and Linux, dual-booting is the
preferred method. In fact in my experience the performance loss from virtualization is
rather big and in general underestimated. Probably worth a different post in itself as
I have already made several tests regarding this.
Back to GPU: If you need virtualization or running the GPU in a server, then you are out
of luck and due to NVIDIAs licensing agreement, you will need to buy a much more costly
Quadro or Tesla card (thousands of dollars more for comparable performance!!!). You also 
need this, if you data set doesn't fit into the gaming cards smaller memory.

##  Intel MKL Fix

OK, focus. Back to the topic at hand. Intel Math Kernel library is a high performance
library for, well you guessed right, math operations like [BLAS](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms). Software can be compiled
against Intel MKL or open alternatives like OpenBLAS. If you are using anaconda or
miniconda python distribution and the default anaconda channel (eg. not conda-forge),
numpy and co. will be compiled against Intel MKL. Matlab is also compiled against Intel
MKL and it was actually that community that first realized a huge issue with Intel MKL
and AMD Zen-based CPUs. When Intel MKL detects an AMD CPU, it chooses a much slower
code Path (probably SSE2 if at all) than when detecting an Intel CPU. The Intel CPU will
use either AVX2 or AVX-512 instructions depending on the exact model. So by default
numpy and anything using it on anaconda python with AMD Zen-based CPU has very bad
performance.

Theoretically you have the option to not use anaconda at all and rely on pip but that
is a problem especially on Windows and even more so if you use RDKit. Anaconda is really
the only sustainable way to get RDKit installed on Windows. But don't despair. There is
a very trivial workaround to completely fix the issue on either OS. Simply create a new
environment variable 

`MKL_DEBUG_CPU_TYPE=5` 

and all applications on the system compiled against Intel MKL will now also on AMD CPUs 
use the fast code path. That's it. It's this simple. And I still wrote an essay to get
to the point. Focus!

You can find further information on below two articles from pugetsystems with performance
measurements, example code and graphs:

1. [MKL vs OpenBLAS](https://www.pugetsystems.com/labs/hpc/AMD-Ryzen-3900X-vs-Intel-Xeon-2175W-Python-numpy---MKL-vs-OpenBLAS-1560/)
2. [MKL Fix](https://www.pugetsystems.com/labs/hpc/How-To-Use-MKL-with-AMD-Ryzen-and-Threadripper-CPU-s-Effectively-for-Python-Numpy-And-Other-Applications-1637/)

The take away is that the fix solves the issue and OpenBLAS is almost as fast as Intel
MKL for AVX2. However OpenBLAS does not support AVX-512 and on CPUs that support it 
(Intel Xeon only), Intel MKL offers better performance. AMD CPUs do not support AVX-512
but you get many more cores for the same price which more than compensates for this
deficit.