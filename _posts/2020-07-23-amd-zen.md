---
layout: post
title: AMD Zen-based CPUs
subtitle: About Intel MKL performance
tags: [hardware,performance]
comments: true
---

Computer hardware is something I'm very interested in and in terms of data processing
and performance knowing your hardware or knowing what hardware to buy can really help.

## Need a powerful workstation?

At latest since the release of AMDs Zen2 based CPUs under the Ryzen, Threadripper and
Eypc brands they have become a real competition to Intel again offering significantly
better multi-threaded performance at similar price points. In fact a Workstation with a
64-core Threadripper CPU, a RTX-series based NVIDIA GPU for CUDA/deep learning, 128+GB
of RAM and plenty of SSD storage can be had for around $10K easily. Even for 5K you can
build yourself a very nice workstation.

## RTX Gaming GPUs for AI

I digress but RTX gaming cards are just fine for deep learning as long as you use them
on your local machine directly. As far as I know virtualization if at all only works
with Linux host but even then if you need Windows and Linux, dual-booting is the
preferred method. In fact in my experience the performance loss from virtualization is
rather big and in general underestimated. Probably worth a different post in itself as
I have already made several tests regarding this.
Back to GPU: If you need virtualization or running the GPU in a server, then you are out
of luck and due to NVIDIAs licensing agreement, you need to buy a much more costly
Quadro or Tesla card (thousands of dollars for comparable performance!!!). You also need
this, if you data set doesn't fit into the gaming cards smaller memory.

##  Intel MKL Fix

OK, focus. Back to the topic at hand. Intel Math Kernel library is a high performance
library for, well you guessed right, math operations like BLAS. Software can be compiled
against Intel MKL or open alternatives like OpenBLAS. If you are using anaconda or
miniconda python distribution and the default anaconda channel (eg. not conda-forge),
numpy and co. will be compiled against Intel MKL. Matlab is also compiled against Intel
MKL and it was actually that community that first realized a huge issue with Intel MKL
and AMD Zen-based CPUs. When Intel MKL detects and AMD CPU, it chooses a much slower
code Path (probably SSE2 if at all) than when detecting an Intel CPU. The Intel CPU will
use either AVX2 or AVX-512 instructions depending on the exact model. So by default
numpy and anything using it on anaconda python with AMD Zen-based CPU is very bad
performance.

Theoretically you have the option to not use anaconda at all and rely on pip but that
is a problem especially on Windows and even more so if you use RDKit. Anaconda is really
the only sustainable way to get RDKit installed on Windows. But don't despair. There is
a very trivial workaround to completely fix the issue on either OS. Simply create a new
environment variable 

`MKL_DEBUG_CPU_TYPE=5` 

and all applications on the system compiled
against Intel MKL will now also on AMD CPUs use the fast code path. That's it. It's this
simple and I still wrote an essay to get to the point.

You can find further information on below to articles from pugetsystems with performance
measurements, example code and graphs:

1. [MKL vs OpenBLAS](https://www.pugetsystems.com/labs/hpc/AMD-Ryzen-3900X-vs-Intel-Xeon-2175W-Python-numpy---MKL-vs-OpenBLAS-1560/)
2. [MKL Fix](https://www.pugetsystems.com/labs/hpc/How-To-Use-MKL-with-AMD-Ryzen-and-Threadripper-CPU-s-Effectively-for-Python-Numpy-And-Other-Applications-1637/)

The take away is that the fix solves the issue and OpenBLAS is almost as fast as Intel
MKL for AVX2. However OpenBLAS does not support AVX-512 and on CPUs that support it 
(Intel Xeon only), Intel MKL offers better performance. AMD CPUs do not support AVX-512
but you get many more cores for the same price which more than compensates for this
deficit.